

PREREQUISITES:

Python 3.8 or higher
Unix command-line utilities: 
- jq
- pipenv


Library dependencies:
- postgresql-client
- postgresql-contrib
- libpq-dev
- libmagic1


Remember to replace the WAPI_KEY environment variable in the Dockerfile with the actual value
of the Weather API key.

++++++++++++++++++++++++++++++++++

NOTE: ONE OF THE ZIPCODES IN THE TEST SET (07030) IS NOT VALID.

This will not crash out the pipeline; you will see the errors emitted to the console
as the pipeline runs, but the remaining valid zipcode will still be processed correctly.

++++++++++++++++++++++++++++++++++

To set up the tooling environment (in a NATIVE context) and run the data pipelines:

 - issue "pipenv install" to install the Python dependencies
 - issue "pipenv shell" to start the virtual environment
 - set the necessary environment vars: 

	WMX_HOME (this should be the repository root directory)
	WAPI_KEY (this should be the key for the Weather API)
	PYTHONPATH must include the repository root directory. ( export PYTHONPATH=`pwd` )

Then, at the shell prompt, issue:

 make process-data
 make process-data-hourly

and check the <repo_root>/data directory for the outputs.


++++++++++++++++++++++++++++++++++

To set up the tooling environment (in a DOCKER context) and run the data pipelines:

!!! You MUST modify the Dockerfile and put a valid WeatherAPI key in the indicated location.

Then issue: 

 docker build -t wmxapp .
 docker run -dt wmxapp
 docker exec -it <proc_name> bash

Then, at the container's shell prompt, issue:

 make process-data
 make process-data-hourly

and check the <repo_root>/data directory for the outputs.

++++++++++++++++++++++++++++++++++
+
+ Makefile instrumentation: "makeblocks"

The Makefile contains some comments which contain a particular syntax of the form:

+open-varblock(...)
+open-cmdblock(...)

and so on. These comments are part of the data pipeline testing and instrumentation system. Do not alter or remove them
unless you know what you are doing.
